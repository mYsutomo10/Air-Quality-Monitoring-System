{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Setup dan Import\n",
    "!pip install -q apache-beam[gcp]\n",
    "!pip install -q google-cloud-aiplatform\n",
    "!pip install -q google-cloud-bigquery\n",
    "!pip install -q google-cloud-firestore\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.io.gcp.bigquery import WriteToBigQuery\n",
    "from apache_beam.io.gcp.firestore import WriteToFirestore\n",
    "import json\n",
    "import datetime\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Setup project\n",
    "PROJECT_ID = \"your-project-id\"\n",
    "BUCKET = \"your-bucket\"\n",
    "REGION = \"your-region\"\n",
    "ENDPOINT_NAME = \"air-quality-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define schema untuk BigQuery\n",
    "SCHEMA = {\n",
    "    'fields': [\n",
    "        {'name': 'timestamp', 'type': 'TIMESTAMP'},\n",
    "        {'name': 'device_id', 'type': 'STRING'},\n",
    "        {'name': 'raw_pm25', 'type': 'FLOAT'},\n",
    "        {'name': 'raw_pm10', 'type': 'FLOAT'},\n",
    "        {'name': 'raw_o3', 'type': 'FLOAT'},\n",
    "        {'name': 'raw_co', 'type': 'FLOAT'},\n",
    "        {'name': 'raw_no2', 'type': 'FLOAT'},\n",
    "        {'name': 'calibrated_pm25', 'type': 'FLOAT'},\n",
    "        {'name': 'calibrated_pm10', 'type': 'FLOAT'},\n",
    "        {'name': 'calibrated_o3', 'type': 'FLOAT'},\n",
    "        {'name': 'calibrated_co', 'type': 'FLOAT'},\n",
    "        {'name': 'calibrated_no2', 'type': 'FLOAT'},\n",
    "        {'name': 'temperature', 'type': 'FLOAT'},\n",
    "        {'name': 'humidity', 'type': 'FLOAT'}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define transformasi untuk pipeline\n",
    "class PreprocessData(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        \"\"\"Preprocess raw data dari IoT devices\"\"\"\n",
    "        try:\n",
    "            # Parse JSON\n",
    "            data = json.loads(element)\n",
    "            \n",
    "            # Validasi data\n",
    "            required_fields = [\n",
    "                'timestamp', 'device_id', 'pm25', 'pm10', \n",
    "                'o3', 'co', 'no2', 'temperature', 'humidity'\n",
    "            ]\n",
    "            \n",
    "            if not all(field in data for field in required_fields):\n",
    "                return []\n",
    "            \n",
    "            # Format data\n",
    "            processed = {\n",
    "                'timestamp': datetime.datetime.fromisoformat(data['timestamp']),\n",
    "                'device_id': data['device_id'],\n",
    "                'raw_pm25': float(data['pm25']),\n",
    "                'raw_pm10': float(data['pm10']),\n",
    "                'raw_o3': float(data['o3']),\n",
    "                'raw_co': float(data['co']),\n",
    "                'raw_no2': float(data['no2']),\n",
    "                'temperature': float(data['temperature']),\n",
    "                'humidity': float(data['humidity'])\n",
    "            }\n",
    "            \n",
    "            return [processed]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing data: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "class CalibrationTransform(beam.DoFn):\n",
    "    def setup(self):\n",
    "        \"\"\"Initialize Vertex AI endpoint\"\"\"\n",
    "        self.endpoint = aiplatform.Endpoint(\n",
    "            endpoint_name=f\"projects/{PROJECT_ID}/locations/{REGION}/endpoints/{ENDPOINT_NAME}\"\n",
    "        )\n",
    "    \n",
    "    def process(self, element):\n",
    "        try:\n",
    "            # Prepare data for prediction\n",
    "            instance = {\n",
    "                'pm25': element['raw_pm25'],\n",
    "                'pm10': element['raw_pm10'],\n",
    "                'o3': element['raw_o3'],\n",
    "                'co': element['raw_co'],\n",
    "                'no2': element['raw_no2'],\n",
    "                'temperature': element['temperature'],\n",
    "                'humidity': element['humidity']\n",
    "            }\n",
    "            \n",
    "            # Get predictions from endpoint\n",
    "            response = self.endpoint.predict(instances=[instance])\n",
    "            calibrated = response.predictions[0]\n",
    "            \n",
    "            # Combine raw and calibrated data\n",
    "            output = element.copy()\n",
    "            output.update({\n",
    "                'calibrated_pm25': calibrated['pm25_calibrated'],\n",
    "                'calibrated_pm10': calibrated['pm10_calibrated'],\n",
    "                'calibrated_o3': calibrated['o3_calibrated'],\n",
    "                'calibrated_co': calibrated['co_calibrated'],\n",
    "                'calibrated_no2': calibrated['no2_calibrated']\n",
    "            })\n",
    "            \n",
    "            return [output]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in calibration: {str(e)}\")\n",
    "            return [element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define pipeline\n",
    "def build_pipeline(pipeline_args=None):\n",
    "    pipeline_options = PipelineOptions(\n",
    "        pipeline_args,\n",
    "        streaming=True,\n",
    "        project=PROJECT_ID,\n",
    "        region=REGION,\n",
    "        job_name='air-quality-pipeline'\n",
    "    )\n",
    "    \n",
    "    with beam.Pipeline(options=pipeline_options) as pipeline:\n",
    "        # Read from Pub/Sub\n",
    "        raw_data = (pipeline\n",
    "                   | 'Read from PubSub' >> beam.io.ReadFromPubSub(\n",
    "                       topic=f'projects/{PROJECT_ID}/topics/air-quality-data'\n",
    "                   )\n",
    "                   | 'Decode' >> beam.Map(lambda x: x.decode('utf-8')))\n",
    "        \n",
    "        # Process data\n",
    "        processed_data = (raw_data\n",
    "                         | 'Preprocess' >> beam.ParDo(PreprocessData())\n",
    "                         | 'Calibrate' >> beam.ParDo(CalibrationTransform()))\n",
    "        \n",
    "        # Write to BigQuery\n",
    "        (processed_data\n",
    "         | 'Write to BigQuery' >> WriteToBigQuery(\n",
    "             table=f'{PROJECT_ID}:air_quality.measurements',\n",
    "             schema=SCHEMA,\n",
    "             write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND,\n",
    "             create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED\n",
    "         ))\n",
    "        \n",
    "        # Write to Firestore\n",
    "        (processed_data\n",
    "         | 'Format for Firestore' >> beam.Map(\n",
    "             lambda x: {\n",
    "                 'document_id': f\"{x['device_id']}_{x['timestamp'].strftime('%Y%m%d%H%M%S')}\",\n",
    "                 'data': x\n",
    "             }\n",
    "         )\n",
    "         | 'Write to Firestore' >> WriteToFirestore(\n",
    "             project_id=PROJECT_ID,\n",
    "             collection='air_quality_measurements'\n",
    "         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Test pipeline locally\n",
    "def test_pipeline():\n",
    "    # Test data\n",
    "    test_data = {\n",
    "        'timestamp': '2025-02-24T10:00:00',\n",
    "        'device_id': 'test-device-001',\n",
    "        'pm25': 25.0,\n",
    "        'pm10': 45.0,\n",
    "        'o3': 0.035,\n",
    "        'co': 1.2,\n",
    "        'no2': 0.045,\n",
    "        'temperature': 25.0,\n",
    "        'humidity': 65.0\n",
    "    }\n",
    "    \n",
    "    # Run preprocessor\n",
    "    preprocessor = PreprocessData()\n",
    "    processed = next(preprocessor.process(json.dumps(test_data)))\n",
    "    print(\"Preprocessed data:\", processed)\n",
    "    \n",
    "    # Run calibration\n",
    "    calibrator = CalibrationTransform()\n",
    "    calibrator.setup()\n",
    "    calibrated = next(calibrator.process(processed))\n",
    "    print(\"Calibrated data:\", calibrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Run test\n",
    "test_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Deploy pipeline\n",
    "if __name__ == '__main__':\n",
    "    build_pipeline([\n",
    "        '--runner=DataflowRunner',\n",
    "        f'--project={PROJECT_ID}',\n",
    "        f'--region={REGION}',\n",
    "        '--streaming'\n",
    "    ])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
