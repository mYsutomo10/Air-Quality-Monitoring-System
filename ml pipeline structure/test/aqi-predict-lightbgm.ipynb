{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'your-project-id'\n",
    "BUCKET_NAME = 'your-bucket-name'\n",
    "MODEL_PATH = 'models/aqi_prediction_model.pkl'\n",
    "SCALER_PATH = 'models/aqi_prediction_scaler.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def read_data_from_gcs(bucket_name, blob_name):\n",
    "    client = storage.Client(project=PROJECT_ID)\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    \n",
    "    data = blob.download_as_string()\n",
    "    df = pd.read_csv(pd.io.common.StringIO(data.decode('utf-8')))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def save_model_to_gcs(model, bucket_name, blob_name):\n",
    "    client = storage.Client(project=PROJECT_ID)\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    temp_path = '/tmp/model.pkl'\n",
    "    joblib.dump(model, temp_path)\n",
    "    \n",
    "    blob.upload_from_filename(temp_path)\n",
    "    print(f\"Model saved to gs://{bucket_name}/{blob_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_time_features(df):\n",
    "    \"\"\"Membuat fitur waktu dari kolom timestamp.\"\"\"\n",
    "    # Pastikan timestamp adalah dalam format datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['timestamp']):\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    df['is_weekend'] = df['timestamp'].dt.dayofweek >= 5\n",
    "    \n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour']/24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour']/24)\n",
    "    \n",
    "    df['is_morning'] = (df['hour'] >= 6) & (df['hour'] < 12)\n",
    "    df['is_afternoon'] = (df['hour'] >= 12) & (df['hour'] < 18)\n",
    "    df['is_evening'] = (df['hour'] >= 18) & (df['hour'] < 22)\n",
    "    df['is_night'] = (df['hour'] >= 22) | (df['hour'] < 6)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_lag_features(df, columns, lag_periods=[1, 2, 3, 6]):\n",
    "    \"\"\"Membuat fitur lag untuk kolom yang ditentukan.\"\"\"\n",
    "    for col in columns:\n",
    "        for lag in lag_periods:\n",
    "            df[f'{col}_lag_{lag}'] = df[col].shift(lag)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_rolling_features(df, columns, windows=[2, 3, 6]):\n",
    "    \"\"\"Membuat fitur rolling untuk kolom yang ditentukan.\"\"\"\n",
    "    for col in columns:\n",
    "        for window in windows:\n",
    "            df[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
    "            df[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"Fungsi utama untuk memproses data.\"\"\"\n",
    "    processed_df = df.copy()\n",
    "    \n",
    "    for col in processed_df.columns:\n",
    "        if processed_df[col].dtype in [np.float64, np.int64]:\n",
    "            processed_df[col] = processed_df[col].fillna(processed_df[col].median())\n",
    "    \n",
    "    processed_df = create_time_features(processed_df)\n",
    "    \n",
    "    sensor_cols = ['pm2_5', 'pm10', 'o3', 'co', 'no2']\n",
    "    weather_cols = ['temperature', 'humidity', 'wind_speed', 'wind_direction']\n",
    "    \n",
    "    processed_df = create_lag_features(processed_df, sensor_cols + weather_cols)\n",
    "    processed_df = create_rolling_features(processed_df, sensor_cols + weather_cols)\n",
    "    processed_df = create_interaction_features(processed_df)\n",
    "    \n",
    "    processed_df = processed_df.dropna()\n",
    "    \n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_prediction_model(df, forecast_horizon=6, target_col='aqi'):\n",
    "    \"\"\"\n",
    "    Membangun model untuk memprediksi AQI beberapa jam ke depan.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame dengan data historis\n",
    "        forecast_horizon: Jumlah jam ke depan untuk prediksi (default: 6)\n",
    "        target_col: Nama kolom target (default: 'aqi')\n",
    "    \"\"\"\n",
    "    # Shifting target untuk setiap horizon prediksi\n",
    "    for h in range(1, forecast_horizon + 1):\n",
    "        df[f'{target_col}_plus_{h}h'] = df[target_col].shift(-h)\n",
    "    \n",
    "    models = {}\n",
    "    metrics = {}\n",
    "    \n",
    "    for h in range(1, forecast_horizon + 1):\n",
    "        target = f'{target_col}_plus_{h}h'\n",
    "        print(f\"\\nBuilding model for {h}-hour ahead prediction\")\n",
    "        \n",
    "        horizon_df = df.dropna(subset=[target])\n",
    "        \n",
    "        X = horizon_df.drop(columns=[col for col in horizon_df.columns if col.startswith(f'{target_col}_plus_')] + [target_col, 'timestamp'])\n",
    "        y = horizon_df[target]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "        categorical_cols = [col for col in X.columns if col not in numeric_cols]\n",
    "        \n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), numeric_cols),\n",
    "                ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "            ])\n",
    "        \n",
    "        model = lgb.LGBMRegressor(\n",
    "            objective='regression',\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=7,\n",
    "            num_leaves=31,\n",
    "            min_data_in_leaf=20,\n",
    "            reg_alpha=0.1,\n",
    "            reg_lambda=0.1,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        metrics[h] = {'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "        models[h] = pipeline\n",
    "        \n",
    "        print(f\"Horizon: +{h} jam | RMSE: {rmse:.2f} | MAE: {mae:.2f} | RÂ²: {r2:.2f}\")\n",
    "    \n",
    "    return models, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_save_models():\n",
    "    \"\"\"Melatih dan menyimpan model ke GCS bucket.\"\"\"\n",
    "    # Baca data dari GCS\n",
    "    sensors_weather_data = read_data_from_gcs(BUCKET_NAME, 'processed_data/sensors_weather_combined.csv')\n",
    "    \n",
    "    print(\"Data shape:\", sensors_weather_data.shape)\n",
    "    print(\"Columns:\", sensors_weather_data.columns.tolist())\n",
    "    \n",
    "    print(\"Preprocessing data...\")\n",
    "    processed_df = preprocess_data(sensors_weather_data)\n",
    "    \n",
    "    print(\"Building models for 6-hour forecasting horizon...\")\n",
    "    models, metrics = build_prediction_model(processed_df, forecast_horizon=6)\n",
    "    \n",
    "    # Visualisasi metrik per horizon\n",
    "    horizons = list(metrics.keys())\n",
    "    rmse_values = [metrics[h]['rmse'] for h in horizons]\n",
    "    mae_values = [metrics[h]['mae'] for h in horizons]\n",
    "    r2_values = [metrics[h]['r2'] for h in horizons]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(horizons, rmse_values, 'o-', linewidth=2)\n",
    "    plt.title('RMSE by Forecast Horizon')\n",
    "    plt.xlabel('Hours Ahead')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(horizons, mae_values, 'o-', linewidth=2)\n",
    "    plt.title('MAE by Forecast Horizon')\n",
    "    plt.xlabel('Hours Ahead')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(horizons, r2_values, 'o-', linewidth=2)\n",
    "    plt.title('RÂ² by Forecast Horizon')\n",
    "    plt.xlabel('Hours Ahead')\n",
    "    plt.ylabel('RÂ²')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/tmp/forecast_metrics.png')\n",
    "    \n",
    "    client = storage.Client(project=PROJECT_ID)\n",
    "    bucket = client.get_bucket(BUCKET_NAME)\n",
    "    blob = bucket.blob('model_evaluation/forecast_metrics.png')\n",
    "    blob.upload_from_filename('/tmp/forecast_metrics.png')\n",
    "    \n",
    "    for h, model in models.items():\n",
    "        save_model_to_gcs(model, BUCKET_NAME, f'models/aqi_prediction_h{h}_model.pkl')\n",
    "\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'horizon': horizons,\n",
    "        'rmse': rmse_values,\n",
    "        'mae': mae_values,\n",
    "        'r2': r2_values\n",
    "    })\n",
    "    \n",
    "    metrics_df.to_csv('/tmp/model_metrics.csv', index=False)\n",
    "    blob = bucket.blob('model_evaluation/model_metrics.csv')\n",
    "    blob.upload_from_filename('/tmp/model_metrics.csv')\n",
    "    \n",
    "    print(\"Training and evaluation complete. Models saved to GCS bucket.\")\n",
    "    return models, metrics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
